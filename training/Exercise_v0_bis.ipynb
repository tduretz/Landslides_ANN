{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Plots, Flux, DataFrames, CSV, ProgressMeter, Statistics\n",
    "import MLUtils: splitobs, normalise\n",
    "import BSON: @save\n",
    "max_epochs = 10\n",
    "frac_train = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5185Ã—9 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">5160 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">dist_roads</th><th style = \"text-align: left;\">DEM</th><th style = \"text-align: left;\">TWI</th><th style = \"text-align: left;\">plan_curvature</th><th style = \"text-align: left;\">profil_curvature</th><th style = \"text-align: left;\">Slope</th><th style = \"text-align: left;\">Geology</th><th style = \"text-align: left;\">LandCover</th><th style = \"text-align: left;\">LS</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">90.1388</td><td style = \"text-align: right;\">957.1</td><td style = \"text-align: right;\">10.0174</td><td style = \"text-align: right;\">0.00257542</td><td style = \"text-align: right;\">1.56e-5</td><td style = \"text-align: right;\">11.0455</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">282.843</td><td style = \"text-align: right;\">536.1</td><td style = \"text-align: right;\">9.21162</td><td style = \"text-align: right;\">-0.00012923</td><td style = \"text-align: right;\">-0.000289093</td><td style = \"text-align: right;\">3.57188</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">21</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">90.1388</td><td style = \"text-align: right;\">768.1</td><td style = \"text-align: right;\">10.0824</td><td style = \"text-align: right;\">0.00623542</td><td style = \"text-align: right;\">-0.00240442</td><td style = \"text-align: right;\">44.0343</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">79.0569</td><td style = \"text-align: right;\">449.4</td><td style = \"text-align: right;\">7.35267</td><td style = \"text-align: right;\">0.00420136</td><td style = \"text-align: right;\">0.00116142</td><td style = \"text-align: right;\">11.3254</td><td style = \"text-align: right;\">24</td><td style = \"text-align: right;\">21</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">25.0</td><td style = \"text-align: right;\">784.8</td><td style = \"text-align: right;\">8.60168</td><td style = \"text-align: right;\">0.00208871</td><td style = \"text-align: right;\">-0.00271119</td><td style = \"text-align: right;\">19.0155</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">25.0</td><td style = \"text-align: right;\">991.5</td><td style = \"text-align: right;\">13.7942</td><td style = \"text-align: right;\">-0.00129205</td><td style = \"text-align: right;\">0.00126791</td><td style = \"text-align: right;\">8.28275</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">21</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">35.3553</td><td style = \"text-align: right;\">569.2</td><td style = \"text-align: right;\">8.86016</td><td style = \"text-align: right;\">-0.00346738</td><td style = \"text-align: right;\">0.00069258</td><td style = \"text-align: right;\">23.9199</td><td style = \"text-align: right;\">24</td><td style = \"text-align: right;\">31</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">70.7107</td><td style = \"text-align: right;\">1211.4</td><td style = \"text-align: right;\">9.46106</td><td style = \"text-align: right;\">-0.00180184</td><td style = \"text-align: right;\">-0.00452195</td><td style = \"text-align: right;\">21.2627</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">21</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">413.824</td><td style = \"text-align: right;\">1592.5</td><td style = \"text-align: right;\">8.28995</td><td style = \"text-align: right;\">-0.00207019</td><td style = \"text-align: right;\">0.00560989</td><td style = \"text-align: right;\">38.1138</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">31</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">348.21</td><td style = \"text-align: right;\">1401.5</td><td style = \"text-align: right;\">9.28837</td><td style = \"text-align: right;\">0.00270649</td><td style = \"text-align: right;\">-0.00561363</td><td style = \"text-align: right;\">27.4877</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">21</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">25.0</td><td style = \"text-align: right;\">609.6</td><td style = \"text-align: right;\">12.9112</td><td style = \"text-align: right;\">-0.0217088</td><td style = \"text-align: right;\">0.00533134</td><td style = \"text-align: right;\">21.3361</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">35.3553</td><td style = \"text-align: right;\">744.4</td><td style = \"text-align: right;\">10.0972</td><td style = \"text-align: right;\">-1.55e-5</td><td style = \"text-align: right;\">-0.00481565</td><td style = \"text-align: right;\">18.507</td><td style = \"text-align: right;\">24</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">513.0</td><td style = \"text-align: right;\">11.7801</td><td style = \"text-align: right;\">-0.00225886</td><td style = \"text-align: right;\">0.0051012</td><td style = \"text-align: right;\">17.2758</td><td style = \"text-align: right;\">24</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">1</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5174</td><td style = \"text-align: right;\">247.487</td><td style = \"text-align: right;\">1328.6</td><td style = \"text-align: right;\">10.1545</td><td style = \"text-align: right;\">-0.00176305</td><td style = \"text-align: right;\">0.00223714</td><td style = \"text-align: right;\">11.0066</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">21</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5175</td><td style = \"text-align: right;\">111.803</td><td style = \"text-align: right;\">935.3</td><td style = \"text-align: right;\">6.57926</td><td style = \"text-align: right;\">0.000745451</td><td style = \"text-align: right;\">0.00522553</td><td style = \"text-align: right;\">40.9607</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5176</td><td style = \"text-align: right;\">1367.71</td><td style = \"text-align: right;\">1411.6</td><td style = \"text-align: right;\">6.69576</td><td style = \"text-align: right;\">-0.00147393</td><td style = \"text-align: right;\">0.00508622</td><td style = \"text-align: right;\">37.6903</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5177</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">698.4</td><td style = \"text-align: right;\">10.8343</td><td style = \"text-align: right;\">0.000130822</td><td style = \"text-align: right;\">0.00365055</td><td style = \"text-align: right;\">9.09908</td><td style = \"text-align: right;\">24</td><td style = \"text-align: right;\">21</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5178</td><td style = \"text-align: right;\">550.568</td><td style = \"text-align: right;\">1499.2</td><td style = \"text-align: right;\">8.42238</td><td style = \"text-align: right;\">0.00542759</td><td style = \"text-align: right;\">-0.00193218</td><td style = \"text-align: right;\">7.82544</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">21</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5179</td><td style = \"text-align: right;\">195.256</td><td style = \"text-align: right;\">1338.4</td><td style = \"text-align: right;\">8.78591</td><td style = \"text-align: right;\">0.00222917</td><td style = \"text-align: right;\">0.00286882</td><td style = \"text-align: right;\">15.9947</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">21</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5180</td><td style = \"text-align: right;\">55.9017</td><td style = \"text-align: right;\">495.9</td><td style = \"text-align: right;\">10.3554</td><td style = \"text-align: right;\">-0.000160022</td><td style = \"text-align: right;\">0.000159998</td><td style = \"text-align: right;\">3.41456</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">21</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5181</td><td style = \"text-align: right;\">70.7107</td><td style = \"text-align: right;\">443.4</td><td style = \"text-align: right;\">11.9715</td><td style = \"text-align: right;\">-0.000120202</td><td style = \"text-align: right;\">3.99e-5</td><td style = \"text-align: right;\">1.58431</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">21</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5182</td><td style = \"text-align: right;\">55.9017</td><td style = \"text-align: right;\">460.6</td><td style = \"text-align: right;\">11.8599</td><td style = \"text-align: right;\">6.4e-5</td><td style = \"text-align: right;\">0.000383965</td><td style = \"text-align: right;\">4.04307</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">31</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5183</td><td style = \"text-align: right;\">55.9017</td><td style = \"text-align: right;\">1032.8</td><td style = \"text-align: right;\">11.8693</td><td style = \"text-align: right;\">-0.000550569</td><td style = \"text-align: right;\">-7.09e-5</td><td style = \"text-align: right;\">4.75323</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">21</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5184</td><td style = \"text-align: right;\">458.939</td><td style = \"text-align: right;\">895.5</td><td style = \"text-align: right;\">8.91429</td><td style = \"text-align: right;\">-0.003389</td><td style = \"text-align: right;\">0.00749098</td><td style = \"text-align: right;\">33.9126</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5185</td><td style = \"text-align: right;\">500.0</td><td style = \"text-align: right;\">576.2</td><td style = \"text-align: right;\">9.6554</td><td style = \"text-align: right;\">0.000434234</td><td style = \"text-align: right;\">0.000594097</td><td style = \"text-align: right;\">2.29349</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& dist\\_roads & DEM & TWI & plan\\_curvature & profil\\_curvature & Slope & Geology & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 90.1388 & 957.1 & 10.0174 & 0.00257542 & 1.56e-5 & 11.0455 & 2 & $\\dots$ \\\\\n",
       "\t2 & 282.843 & 536.1 & 9.21162 & -0.00012923 & -0.000289093 & 3.57188 & 1 & $\\dots$ \\\\\n",
       "\t3 & 90.1388 & 768.1 & 10.0824 & 0.00623542 & -0.00240442 & 44.0343 & 2 & $\\dots$ \\\\\n",
       "\t4 & 79.0569 & 449.4 & 7.35267 & 0.00420136 & 0.00116142 & 11.3254 & 24 & $\\dots$ \\\\\n",
       "\t5 & 25.0 & 784.8 & 8.60168 & 0.00208871 & -0.00271119 & 19.0155 & 1 & $\\dots$ \\\\\n",
       "\t6 & 25.0 & 991.5 & 13.7942 & -0.00129205 & 0.00126791 & 8.28275 & 9 & $\\dots$ \\\\\n",
       "\t7 & 35.3553 & 569.2 & 8.86016 & -0.00346738 & 0.00069258 & 23.9199 & 24 & $\\dots$ \\\\\n",
       "\t8 & 70.7107 & 1211.4 & 9.46106 & -0.00180184 & -0.00452195 & 21.2627 & 9 & $\\dots$ \\\\\n",
       "\t9 & 413.824 & 1592.5 & 8.28995 & -0.00207019 & 0.00560989 & 38.1138 & 7 & $\\dots$ \\\\\n",
       "\t10 & 348.21 & 1401.5 & 9.28837 & 0.00270649 & -0.00561363 & 27.4877 & 1 & $\\dots$ \\\\\n",
       "\t11 & 25.0 & 609.6 & 12.9112 & -0.0217088 & 0.00533134 & 21.3361 & 1 & $\\dots$ \\\\\n",
       "\t12 & 35.3553 & 744.4 & 10.0972 & -1.55e-5 & -0.00481565 & 18.507 & 24 & $\\dots$ \\\\\n",
       "\t13 & 0.0 & 513.0 & 11.7801 & -0.00225886 & 0.0051012 & 17.2758 & 24 & $\\dots$ \\\\\n",
       "\t14 & 134.629 & 1417.1 & 10.1081 & 0.00190051 & 0.00382082 & 18.3184 & 1 & $\\dots$ \\\\\n",
       "\t15 & 276.134 & 657.9 & 15.1871 & -0.00868673 & 0.00107314 & 4.28039 & 1 & $\\dots$ \\\\\n",
       "\t16 & 838.153 & 1317.4 & 9.24432 & -0.00736158 & 0.0198382 & 25.7949 & 11 & $\\dots$ \\\\\n",
       "\t17 & 25.0 & 1454.6 & 7.77506 & -0.00236358 & -0.00236338 & 27.7049 & 1 & $\\dots$ \\\\\n",
       "\t18 & 520.216 & 1555.1 & 9.77061 & 0.00319704 & -0.00448284 & 29.7296 & 11 & $\\dots$ \\\\\n",
       "\t19 & 265.754 & 722.1 & 7.51074 & 0.00539032 & -0.0114095 & 18.8805 & 24 & $\\dots$ \\\\\n",
       "\t20 & 575.543 & 719.0 & 9.17031 & -0.00708939 & 0.0244306 & 35.5879 & 11 & $\\dots$ \\\\\n",
       "\t21 & 55.9017 & 1060.8 & 9.37975 & 0.00369933 & 1.89e-5 & 20.2708 & 1 & $\\dots$ \\\\\n",
       "\t22 & 660.019 & 1595.3 & 7.94601 & 0.000422263 & -0.00629785 & 41.5159 & 2 & $\\dots$ \\\\\n",
       "\t23 & 515.388 & 1507.0 & 13.6804 & -0.0130615 & -0.0111415 & 31.2148 & 31 & $\\dots$ \\\\\n",
       "\t24 & 645.174 & 745.7 & 11.424 & -0.00078781 & -0.000147967 & 4.68653 & 7 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5185Ã—9 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0mâ”‚\u001b[1m dist_roads \u001b[0m\u001b[1m DEM     \u001b[0m\u001b[1m TWI      \u001b[0m\u001b[1m plan_curvature \u001b[0m\u001b[1m profil_curvature \u001b[0m\u001b[1m Slope\u001b[0m â‹¯\n",
       "      â”‚\u001b[90m Float64    \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64        \u001b[0m\u001b[90m Float64          \u001b[0m\u001b[90m Float\u001b[0m â‹¯\n",
       "â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "    1 â”‚    90.1388    957.1  10.0174      0.00257542        1.56e-5      11.04 â‹¯\n",
       "    2 â”‚   282.843     536.1   9.21162    -0.00012923       -0.000289093   3.57\n",
       "    3 â”‚    90.1388    768.1  10.0824      0.00623542       -0.00240442   44.03\n",
       "    4 â”‚    79.0569    449.4   7.35267     0.00420136        0.00116142   11.32\n",
       "    5 â”‚    25.0       784.8   8.60168     0.00208871       -0.00271119   19.01 â‹¯\n",
       "    6 â”‚    25.0       991.5  13.7942     -0.00129205        0.00126791    8.28\n",
       "    7 â”‚    35.3553    569.2   8.86016    -0.00346738        0.00069258   23.91\n",
       "    8 â”‚    70.7107   1211.4   9.46106    -0.00180184       -0.00452195   21.26\n",
       "  â‹®   â”‚     â‹®          â‹®        â‹®            â‹®                â‹®             â‹®  â‹±\n",
       " 5179 â”‚   195.256    1338.4   8.78591     0.00222917        0.00286882   15.99 â‹¯\n",
       " 5180 â”‚    55.9017    495.9  10.3554     -0.000160022       0.000159998   3.41\n",
       " 5181 â”‚    70.7107    443.4  11.9715     -0.000120202       3.99e-5       1.58\n",
       " 5182 â”‚    55.9017    460.6  11.8599      6.4e-5            0.000383965   4.04\n",
       " 5183 â”‚    55.9017   1032.8  11.8693     -0.000550569      -7.09e-5       4.75 â‹¯\n",
       " 5184 â”‚   458.939     895.5   8.91429    -0.003389          0.00749098   33.91\n",
       " 5185 â”‚   500.0       576.2   9.6554      0.000434234       0.000594097   2.29\n",
       "\u001b[36m                                                 4 columns and 5170 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df  = CSV.read(\"data/Landslides.csv\", DataFrame)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9Ã—5185 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n",
       " 1  â‹…  1  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â€¦  1  â‹…  â‹…  â‹…  1  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…\n",
       " â‹…  1  â‹…  â‹…  1  â‹…  â‹…  â‹…  â‹…  1  1  â‹…  â‹…     â‹…  â‹…  1  â‹…  â‹…  1  â‹…  â‹…  â‹…  1  â‹…  1\n",
       " â‹…  â‹…  â‹…  1  â‹…  â‹…  1  â‹…  â‹…  â‹…  â‹…  1  1     â‹…  â‹…  â‹…  1  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…\n",
       " â‹…  â‹…  â‹…  â‹…  â‹…  1  â‹…  1  â‹…  â‹…  â‹…  â‹…  â‹…     â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  1  1  1  â‹…  â‹…  â‹…\n",
       " â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  1  â‹…  â‹…  â‹…  â‹…     â‹…  1  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…\n",
       " â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â€¦  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  1  â‹…\n",
       " â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…     â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…\n",
       " â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…     â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…\n",
       " â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…     â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…  â‹…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# One hot batches for categorical variables\n",
    "LandCover = Flux.onehotbatch(Array(df[:,8]), unique(Array(df[:,8])))\n",
    "Geology   = Flux.onehotbatch(Array(df[:,7]), unique(Array(df[:,7])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6Ã—5185 adjoint(::Matrix{Float64}) with eltype Float64:\n",
       "  90.1388      282.843         90.1388      â€¦  458.939       500.0\n",
       " 957.1         536.1          768.1            895.5         576.2\n",
       "  10.0174        9.21162       10.0824           8.91429       9.6554\n",
       "   0.00257542   -0.00012923     0.00623542      -0.003389      0.000434234\n",
       "   1.56e-5      -0.000289093   -0.00240442       0.00749098    0.000594097\n",
       "  11.0455        3.57188       44.0343      â€¦   33.9126        2.29349"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vectors of length 2, as columns of a matrix:\n",
    "# noisy     = [Array(df[1:500,1:6])'; Geology_train; LandCover_train] # 2Ã—1000 Matrix{Float32}\n",
    "# truth     = Array(df[1:500,9]).==1;  #   1000-element Vector{Bool}\n",
    "X_all  = [ Array(df[:,1:6])'; Geology; LandCover ]\n",
    "X_all  = Array(df[:,1:6])'#; Geology; LandCover ]\n",
    "y_all  = df[:,9].==1\n",
    "# Flux.normalise(X_all)\n",
    "# noisy  = X_all[:,1:500]\n",
    "# truth  = y_all[1:500]\n",
    "# target = Flux.onehotbatch(truth, [true, false]) \n",
    "# println( (size(noisy), size(truth)) )\n",
    "\n",
    "# noisy_test  = X_all[:,501:end]\n",
    "# truth_test  = y_all[501:end]\n",
    "\n",
    "# Split with multiple arrays and shuffling\n",
    "train, test = splitobs((X_all, y_all), at=frac_train, shuffle=true)\n",
    "X_train, Y_train = train\n",
    "X_test,  Y_test  = test\n",
    "noisy       = X_train\n",
    "target      = Flux.onehotbatch(Y_train, [true, false]) \n",
    "noisy_test  = X_test\n",
    "target_test = Flux.onehotbatch(Y_test, [true, false]) \n",
    "\n",
    "X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(6 => 25, tanh),                 \u001b[90m# 175 parameters\u001b[39m\n",
       "  BatchNorm(25),                        \u001b[90m# 50 parameters\u001b[39m\u001b[90m, plus 50\u001b[39m\n",
       "  Dense(25 => 2),                       \u001b[90m# 52 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m        # Total: 6 trainable arrays, \u001b[39m277 parameters,\n",
       "\u001b[90m          # plus 2 non-trainable, 50 parameters, summarysize \u001b[39m1.754 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model = Chain(\n",
    "#     Dense(22 => 25, tanh),   # activation function inside layer\n",
    "#     BatchNorm(25),\n",
    "#     Dense(25 => 22),\n",
    "#     BatchNorm(22),\n",
    "#     Dense(22 => 2),\n",
    "#     softmax) \n",
    "\n",
    "model = Chain(\n",
    "    Dense(6 => 25, tanh),   # activation function inside layer     \n",
    "    BatchNorm(25),\n",
    "    Dense(25 => 2),\n",
    "    softmax\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = model( noisy );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam(0.05, (0.9, 0.999), 1.0e-8, IdDict{Any, Any}())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pars = Flux.params(model)  # contains references to arrays in model\n",
    "opt  = Flux.Adam(0.05)      # will store optimiser momentum, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49-element DataLoader(::Tuple{SubArray{Float64, 2, LinearAlgebra.Adjoint{Float64, Matrix{Float64}}, Tuple{Base.Slice{Base.OneTo{Int64}}, Vector{Int64}}, false}, OneHotArrays.OneHotMatrix{UInt32, Vector{UInt32}}}, shuffle=true, batchsize=64)\n",
       "  with first element:\n",
       "  (6Ã—64 Matrix{Float64}, 2Ã—64 OneHotMatrix(::Vector{UInt32}) with eltype Bool,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To train the model, we use batches of 64 samples, and one-hot encoding:\n",
    "# target = Flux.onehotbatch(truth, [true, false])                   # 2Ã—1000 OneHotMatrix\n",
    "loader = Flux.DataLoader((noisy, target), batchsize=64, shuffle=true);\n",
    "# 16-element DataLoader with first element: (2Ã—64 Matrix{Float32}, 2Ã—64 OneHotMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss1(model, x, y) = Flux.crossentropy(model(x), y);\n",
    "loss1(model, noisy, target)\n",
    "accuracy(x, y) = mean(Flux.onecold(model(x)) .== Flux.onecold(y)) # Define the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss0 = loss1(model, noisy, target) = 1.587354654538221\n",
      "acc0 = accuracy(noisy, target) = 0.49823207971713274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_test0 = accuracy(noisy_test, target_test) = 0.4811957569913211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4811957569913211"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@show loss0     = loss1(model, noisy, target)\n",
    "@show acc0      = accuracy(noisy, target)\n",
    "@show acc_test0 = accuracy(noisy_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1(model, noisy, target) = 0.6939679965220837\n",
      "accuracy(noisy, target) = 0.4927675988428158\n",
      "accuracy(noisy_test, target_test) = 0.5115718418514947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5115718418514947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loop, using the whole data set 1000 times:\n",
    "losses          = []\n",
    "accuracies      = []\n",
    "losses_test     = []\n",
    "accuracies_test = []\n",
    "for epoch in 1:max_epochs #@showprogress \n",
    "    for (x, y) in loader\n",
    "        loss, grad = Flux.withgradient(pars) do\n",
    "            # Evaluate model and loss inside gradient context:\n",
    "            y_hat = model(x)\n",
    "            Flux.crossentropy(y_hat, y)\n",
    "        end\n",
    "        Flux.update!(opt, pars, grad)\n",
    "        #####\n",
    "        push!(losses, loss)  # logging, outside gradient context\n",
    "        accu=accuracy(noisy, target)\n",
    "        push!(accuracies, accu)\n",
    "        #####\n",
    "        loss_test = loss1(model, noisy_test, target_test)\n",
    "        push!(losses_test, loss_test)  # logging, outside gradient context\n",
    "        accu_test =accuracy(noisy_test, target_test)\n",
    "        push!(accuracies_test, accu_test)\n",
    "    end\n",
    "end\n",
    "@show loss1(model, noisy, target)\n",
    "@show accuracy(noisy, target)\n",
    "@show accuracy(noisy_test, target_test)\n",
    "# println(noisy_test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean((out2[1, :] .> 0.5) .== Y_train) = 0.5072324011571842\n",
      "mean((out2[1, :] .< 0.5) .== Y_train) = 0.4927675988428158\n",
      "mean((out2[2, :] .> 0.5) .!= Y_train) = 0.5072324011571842\n",
      "mean((out2[2, :] .< 0.5) .!= Y_train) = 0.4927675988428158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4927675988428158"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out2 = model(noisy)  # first row is prob. of true, second row p(false)\n",
    "@show mean((out2[1,:] .> 0.5) .== Y_train)  # accuracy 94% so far!\n",
    "@show mean((out2[1,:] .< 0.5) .== Y_train)  # accuracy 94% so far!\n",
    "@show mean((out2[2,:] .> 0.5) .!= Y_train)  # accuracy 94% so far!\n",
    "@show mean((out2[2,:] .< 0.5) .!= Y_train)  # accuracy 94% so far!\n",
    "# mean((out2[1,:] .< 0.5) .!= Y_train)  # accuracy 94% so far!\n",
    "# mean((out2[1,:] .> 0.5) .!= Y_train)  # accuracy 94% so far!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_true = scatter(noisy[1,:], noisy[2,:], zcolor=Y_train,   title=\"True classification\", legend=false, c=:turbo, xlabel=names(df)[2], ylabel=names(df)[3] )\n",
    "# p_raw =  scatter(noisy[1,:], noisy[2,:], zcolor=out1[1,:], title=\"Untrained network\", label=\"\", clims=(0,1), c=:turbo, xlabel=names(df)[2], ylabel=names(df)[3] )\n",
    "# p_done = scatter(noisy[1,:], noisy[2,:], zcolor=out2[1,:], title=\"Trained network\", legend=false, c=:turbo, xlabel=names(df)[2], ylabel=names(df)[3] )\n",
    "\n",
    "# plot(p_true, p_raw, p_done, layout=(1,3), size=(1000,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(losses; xaxis=(:log10, \"iteration\"),\n",
    "#     yaxis=\"loss\", label=\"per batch\")\n",
    "# @show n = length(loader)\n",
    "# plot!(n:n:length(losses), mean.(Iterators.partition(losses, n)),\n",
    "#     label=\"epoch mean\", title=\"Loss\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(accuracies; xaxis=(:log10, \"iteration\"),\n",
    "#     yaxis=\"loss\", label=\"per batch\")\n",
    "# @show n = length(loader)\n",
    "# plot!(n:n:length(accuracies), mean.(Iterators.partition(accuracies, n)),\n",
    "#     label=\"epoch mean\", title=\"Accuracy\", dpi=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "309baa410e37084482bcba9b39a5b9e635e78b91cd7553c4b48a2d89780d0f88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
